{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ee88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:  2.3.0\n",
      "Keras Version:  2.4.0\n",
      "../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer\\keras_reg_160_10_002.sav\n",
      "../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer\\keras_reg_jl_160_10_002.sav\n",
      "../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer\\sample_submission.csv\n",
      "../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer\\test.csv\n",
      "../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer\\train.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "#import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from random import seed\n",
    "seed(1)\n",
    "seed = 43\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import image\n",
    "from tensorflow import core\n",
    "from tensorflow.keras import layers\n",
    "print(\"Tensorflow Version: \", tf.__version__)\n",
    "print(\"Keras Version: \",keras.__version__)\n",
    "\n",
    "\n",
    "kaggle = 0 # Kaggle path active = 1\n",
    "\n",
    "# change your local path here\n",
    "if kaggle == 1 :\n",
    "    MNIST_PATH= '../input/digit-recognizer'\n",
    "else:\n",
    "    MNIST_PATH= '../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer'\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(MNIST_PATH): \n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction - MNIST Training Competition\n",
    "This notebook is a fork of my previous developed notebook for digit recognition. Therefore you will find some parts that look common the the notebook <a href=\"https://www.kaggle.com/skiplik/digit-recognition-with-a-deep-neural-network\">Digit Recognition with a Deep Neural Network</a> and some parts that are completely different.\n",
    "\n",
    "With this I want to take a deeper look in some parts of finetuning hyperparameters. The following list shows some of the finetuning parameters which I will take a look into, one or two ore more ... :\n",
    "- Dwindling / Exploding Gradients\n",
    "    - <b>Initializing the Weights</b>\n",
    "    - <b>Batchnormalization</b>\n",
    "    - <s>Gradient Clipping</s>\n",
    "    - <b>Saturated Activataion Functions</b>\n",
    "- Optimizers\n",
    "    - <s>Momentum Optimizers</s>\n",
    "    - <s>Nesterov</s>\n",
    "    - <s>AdaGrad</s>\n",
    "    - <s>RMSProp</s>\n",
    "    - <b>Adam - Optimizer</b>\n",
    "    - <s>Scheduling Learnrate</s>\n",
    "- Regulations\n",
    "    - <s>Drop-Outs</s>\n",
    "    - <b>l1 / l2 - Regulations</b>\n",
    "    - <s>Monte-Carlo Drop-out ???</s>\n",
    "    - <s>Max Norm Regulations ????</s>\n",
    "\n",
    "Not part of this notebook will be the use of pretrained neural networks (Transferlearning). I just want to list this here for the sake of completeness.\n",
    "\n",
    "Link to the data topic: https://www.kaggle.com/c/digit-recognizer/data\n",
    "\n",
    "As in the previous notebooks I will use Tensorflow with Keras. I already mentioned in other notebooks, I will skip some explanations about the data set here. Moreover I will use the already discovered knowledge about the data and transform/prepare the data rightaway.\n",
    "\n",
    "## Notebook Versions with Different Hyperparameter Configurations\n",
    "As described in the part above, I used/tested different hyperparameter settings to get a little bit closer to its effects on the neural network and the network's results. I know that there are parameters that effect other parameters when they have changed (and therefore should have been changed as well), however in these cases I just tried a little bit around. Sometimes I kept one or two parameters together, which should be together (e.g. kernel initializer \"lecun\" and activation function \"selu\") and sometimes not. The main purpose here was to use them and see the results.\n",
    "\n",
    "Therefore on Kaggle you can look in the different versions of this notebook if you are interested. In the following I will list some versions with the used hyperparameter config in it:\n",
    "- Version 7 and 6:\n",
    "    - Activation Function - \"relu\"\n",
    "    - Initializing Weights - \"He Normalization\"\n",
    "    - Batchnormalization\n",
    "- Version 9:\n",
    "    - Activation Function - \"selu\"\n",
    "    - Initializing Weights - \"LeCun Normal\"\n",
    "- Version 12 and 14:\n",
    "    - Regularisation with L1 and L2\n",
    "- Version 15:\n",
    "    - Activation Function - \"relu\"\n",
    "    - Initializing Weights - \"He Normalization\"\n",
    "    - Batchnormalization\n",
    "    - Optimizer - \"Adam\"\n",
    "\n",
    "The current best run was based on the Version 7 with an accuracy of 0.97657 on the kaggle competition \"Digit Recognzier\"\n",
    "\n",
    "\n",
    "## My other Projects\n",
    "If you are interested in some more clearly analysis of the dataset take a look into my other notebooks about the MNIS-dataset:\n",
    "- Digit Recognition with a Deep Neural Network: https://www.kaggle.com/skiplik/digit-recognition-with-a-deep-neural-network\n",
    "- Another MNIST Try: https://www.kaggle.com/skiplik/another-mnist-try\n",
    "- First NN by Detecting Handwritten Characters: https://www.kaggle.com/skiplik/first-nn-by-detecting-handwritten-characters\n",
    "...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path and file\n",
    "CSV_FILE_TRAIN='train.csv'\n",
    "CSV_FILE_TEST='test.csv'\n",
    "\n",
    "def load_mnist_data(minist_path, csv_file):\n",
    "    csv_path = os.path.join(minist_path, csv_file)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "def load_mnist_data_manuel(minist_path, csv_file):\n",
    "    csv_path = os.path.join(minist_path, csv_file)\n",
    "    csv_file = open(csv_path, 'r')\n",
    "    csv_data = csv_file.readlines()\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "def split_train_val(data, val_ratio):\n",
    "    return \n",
    "    \n",
    "\n",
    "train = load_mnist_data(MNIST_PATH,CSV_FILE_TRAIN)\n",
    "test = load_mnist_data(MNIST_PATH,CSV_FILE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['label'].copy()\n",
    "X = train.drop(['label'], axis=1)\n",
    "\n",
    "# competition dataset\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Features:  (42000, 784)\n",
      "Shape of the Labels:  (42000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the Features: \",X.shape)\n",
    "print(\"Shape of the Labels: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Value Count\n",
    "Visualizing the label distribution of the full train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.value_counts('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=seed, test_size=0.20\n",
    "                                                  , stratify=y\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the equally splitted train- and val-sets based on the given label y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Set Distribution\n",
      "1    0.111518\n",
      "7    0.104792\n",
      "3    0.103601\n",
      "9    0.099702\n",
      "2    0.099464\n",
      "6    0.098512\n",
      "0    0.098363\n",
      "4    0.096964\n",
      "8    0.096726\n",
      "5    0.090357\n",
      "Name: label, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Val - Set Distribution\n",
      "1    0.111548\n",
      "7    0.104762\n",
      "3    0.103571\n",
      "9    0.099762\n",
      "2    0.099405\n",
      "0    0.098452\n",
      "6    0.098452\n",
      "4    0.096905\n",
      "8    0.096786\n",
      "5    0.090357\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train - Set Distribution\")\n",
    "print(y_train.value_counts() / y_train.value_counts().sum() )\n",
    "print('--------------------------------------------------------------')\n",
    "print('--------------------------------------------------------------')\n",
    "print('--------------------------------------------------------------')\n",
    "print(\"Val - Set Distribution\")\n",
    "print(y_val.value_counts() / y_val.value_counts().sum() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (42000, 784)\n",
      "X_train:  (33600, 784)\n",
      "X_val:  (8400, 784)\n",
      "y_train:  (33600,)\n",
      "y_val:  (8400,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X: \", X.shape)\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_val: \", X_val.shape)\n",
    "\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_val: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Transforming Piplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    #('normalizer', Normalizer())\n",
    "    ('std_scalar',StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation with Tensorflow Data Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(image):\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]]) * 85 // 100       # croping to 90% of the initial picture \n",
    "    return tf.image.random_crop(image, [min_dim, min_dim, 1])\n",
    "\n",
    "\n",
    "def crop_flip_resize(image, label, flipping = True):\n",
    "    if flipping == True:\n",
    "        cropped_image = random_crop(image)\n",
    "        cropped_image = tf.image.flip_left_right(cropped_image)\n",
    "    else:\n",
    "        cropped_image = random_crop(image)\n",
    "\n",
    "    ## final solution\n",
    "    resized_image = tf.image.resize(cropped_image, [28,28])\n",
    "    final_image = resized_image\n",
    "    #final_image = keras.applications.xception.preprocess_input(resized_image)\n",
    "    return final_image, label  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8400, 784)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting dataframe format into tensorflow compatible format.\n",
    "X_train = X_train.values.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_val = X_val.values.reshape(X_val.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train_crop = X_train.copy()\n",
    "X_val_crop = X_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensorbased dataset \n",
    "\n",
    "training_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(X_train, tf.float32),\n",
    "            tf.cast(y_train, tf.int32)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "val_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "             tf.cast(X_val, tf.float32),\n",
    "             tf.cast(y_val, tf.int32)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "training_crop_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(X_train_crop, tf.float32),\n",
    "            tf.cast(y_train, tf.int32)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "val_crop_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "             tf.cast(X_val_crop, tf.float32),\n",
    "             tf.cast(y_val, tf.int32)\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function random_crop at 0x00000252C9ED0820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function random_crop at 0x00000252C9ED0820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# resizing, croping images via self build function\n",
    "training_crop_dataset = training_crop_dataset.map(partial(crop_flip_resize, flipping=False))\n",
    "val_crop_dataset = val_crop_dataset.map(partial(crop_flip_resize, flipping=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing a croped, flipped, resized image from new dataset.\n",
    "for X_values, y_values in training_crop_dataset.take(1):\n",
    "    for index in range(1):\n",
    "        plt.imshow(X_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate the two datasets\n",
    "training_dataset_all = training_dataset.concatenate(training_crop_dataset)\n",
    "val_dataset_all = val_dataset.concatenate(val_crop_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_dataset_all length:  67200\n",
      "val_dataset_all length:  16800\n"
     ]
    }
   ],
   "source": [
    "print(\"training_dataset_all length: \", len(list(training_dataset_all)))\n",
    "print(\"val_dataset_all length: \", len(list(val_dataset_all)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffeling and batching data\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "train_ds = training_dataset_all.shuffle(10000).batch(32).prefetch(1)\n",
    "val_ds = val_dataset_all.shuffle(8000).batch(32).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Model Visualization with Tensorboard (not for Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative root_logdir:  ../../tensorboard-logs\n"
     ]
    }
   ],
   "source": [
    "root_logdir = \"../../tensorboard-logs\"\n",
    "\n",
    "print(\"Relative root_logdir: \",root_logdir)\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir,run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current run logdir for Tensorboard:  ../../tensorboard-logs\\run_2021_11_11-17_14_50\n"
     ]
    }
   ],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "print(\"Current run logdir for Tensorboard: \", run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../tensorboard-logs\\\\run_2021_11_11-17_14_50'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Callbacks for Tensorboard\n",
    "With Keras there is a way of using Callbacks for the Tensorboard to write log files for the board and visualize the different graphs (loss and val curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "236d0a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(28, 28, 1), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset_all.element_spec[0]\n",
    "##val_dataset_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "\n",
    "input_shape=[784]\n",
    "input_shape_notFlattened=[28,28,1]\n",
    "\n",
    "batch_shape = []\n",
    "\n",
    "\n",
    "learning_rt = 1e-03 \n",
    "activation_fn = \"relu\"\n",
    "initializer = \"he_normal\"\n",
    "regularizer =  None\n",
    "\n",
    "# Model building\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', input_shape=input_shape_notFlattened))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation(activation_fn))\n",
    "#max pooling\n",
    "model.add(keras.layers.Conv2D(filters=128, kernel_size=3, strides=2, padding='same'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation(activation_fn))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rt)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                62730     \n",
      "=================================================================\n",
      "Total params: 137,994\n",
      "Trainable params: 137,610\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_train_model.h5\", save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "   2/2100 [..............................] - ETA: 5:34 - loss: 2.7908 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0110s vs `on_train_batch_end` time: 0.3070s). Check your callbacks.\n",
      "2100/2100 [==============================] - 28s 13ms/step - loss: 0.2286 - accuracy: 0.9319 - val_loss: 0.1347 - val_accuracy: 0.9566\n",
      "Epoch 2/200\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0967 - accuracy: 0.9701 - val_loss: 0.1187 - val_accuracy: 0.9629\n",
      "Epoch 3/200\n",
      "2100/2100 [==============================] - 26s 12ms/step - loss: 0.0692 - accuracy: 0.9781 - val_loss: 0.1663 - val_accuracy: 0.9489\n",
      "Epoch 4/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0525 - accuracy: 0.9833 - val_loss: 0.0796 - val_accuracy: 0.9762\n",
      "Epoch 5/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0393 - accuracy: 0.9871 - val_loss: 0.1167 - val_accuracy: 0.9663\n",
      "Epoch 6/200\n",
      "2100/2100 [==============================] - 28s 13ms/step - loss: 0.0298 - accuracy: 0.9901 - val_loss: 0.0778 - val_accuracy: 0.9786\n",
      "Epoch 7/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.0888 - val_accuracy: 0.9784\n",
      "Epoch 8/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.0892 - val_accuracy: 0.9760\n",
      "Epoch 9/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0941 - val_accuracy: 0.9770\n",
      "Epoch 10/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0988 - val_accuracy: 0.9780\n",
      "Epoch 11/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.1254 - val_accuracy: 0.9720\n",
      "Epoch 12/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.1110 - val_accuracy: 0.9770\n",
      "Epoch 13/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1019 - val_accuracy: 0.9792\n",
      "Epoch 14/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.1081 - val_accuracy: 0.9780\n",
      "Epoch 15/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.1019 - val_accuracy: 0.9790\n",
      "Epoch 16/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.1067 - val_accuracy: 0.9794\n",
      "Epoch 17/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.1165 - val_accuracy: 0.9791\n",
      "Epoch 18/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1181 - val_accuracy: 0.9796\n",
      "Epoch 19/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.1034 - val_accuracy: 0.9799\n",
      "Epoch 20/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.1198 - val_accuracy: 0.9794\n",
      "Epoch 21/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.1210 - val_accuracy: 0.9798\n",
      "Epoch 22/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1304 - val_accuracy: 0.9787\n",
      "Epoch 23/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.1207 - val_accuracy: 0.9808\n",
      "Epoch 24/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1107 - val_accuracy: 0.9812\n",
      "Epoch 25/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.1169 - val_accuracy: 0.9805\n",
      "Epoch 26/200\n",
      "2100/2100 [==============================] - 27s 13ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1310 - val_accuracy: 0.9801\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=200, validation_data=val_ds, callbacks=[checkpoint_cb, keras.callbacks.EarlyStopping(patience=20), tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training with Full Dataset \n",
    "In this part I will train the model with the full dataset. This time I will use the discovered hyperparameters from previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model building\n",
    "model_full = keras.models.Sequential()\n",
    "\n",
    "model_full.add(keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', input_shape=input_shape_notFlattened))\n",
    "model_full.add(keras.layers.BatchNormalization())\n",
    "model_full.add(keras.layers.Activation(activation_fn))\n",
    "model_full.add(keras.layers.Conv2D(filters=128, kernel_size=3, strides=2, padding='same'))\n",
    "model_full.add(keras.layers.BatchNormalization())\n",
    "model_full.add(keras.layers.Activation(activation_fn))\n",
    "model_full.add(keras.layers.Flatten())\n",
    "model_full.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rt)\n",
    "\n",
    "model_full.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 699,146\n",
      "Trainable params: 694,578\n",
      "Non-trainable params: 4,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new log dir for tensorboard\n",
    "tensorboard_cb_f = keras.callbacks.TensorBoard(get_run_logdir())\n",
    "checkpoint_cb_f = keras.callbacks.ModelCheckpoint(\"my_modell_full.h5\", save_best_only=False, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing full features set (X) for the tensorflow data api\n",
    "\n",
    "training_dataset_all = training_dataset.concatenate(training_crop_dataset)\n",
    "val_dataset_all = val_dataset.concatenate(val_crop_dataset)\n",
    "\n",
    "training_ds_all = training_dataset_all.concatenate(val_dataset_all)\n",
    "\n",
    "training_ds_all = training_ds_all.shuffle(20000).batch(32).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "   1/2625 [..............................] - ETA: 0s - loss: 3.2111 - accuracy: 0.0625WARNING:tensorflow:From D:\\anaconda3\\envs\\wingpuflake_keras\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0055s vs `on_train_batch_end` time: 0.0385s). Check your callbacks.\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 1.4008 - accuracy: 0.5414\n",
      "Epoch 2/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.7951 - accuracy: 0.7428\n",
      "Epoch 3/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.6236 - accuracy: 0.7997\n",
      "Epoch 4/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.5300 - accuracy: 0.8311\n",
      "Epoch 5/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.4738 - accuracy: 0.8485\n",
      "Epoch 6/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.4314 - accuracy: 0.8623\n",
      "Epoch 7/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.3993 - accuracy: 0.8721\n",
      "Epoch 8/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.3725 - accuracy: 0.8806\n",
      "Epoch 9/60\n",
      "2625/2625 [==============================] - 11s 4ms/step - loss: 0.3523 - accuracy: 0.8868\n",
      "Epoch 10/60\n",
      "2625/2625 [==============================] - 11s 4ms/step - loss: 0.3305 - accuracy: 0.8931\n",
      "Epoch 11/60\n",
      "2625/2625 [==============================] - 11s 4ms/step - loss: 0.3184 - accuracy: 0.8981\n",
      "Epoch 12/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.3013 - accuracy: 0.9041\n",
      "Epoch 13/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.2900 - accuracy: 0.9066\n",
      "Epoch 14/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.2810 - accuracy: 0.9097\n",
      "Epoch 15/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.2703 - accuracy: 0.9137\n",
      "Epoch 16/60\n",
      "2625/2625 [==============================] - 11s 4ms/step - loss: 0.2615 - accuracy: 0.9165\n",
      "Epoch 17/60\n",
      "2625/2625 [==============================] - 11s 4ms/step - loss: 0.2507 - accuracy: 0.9198\n",
      "Epoch 18/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.2465 - accuracy: 0.9215\n",
      "Epoch 19/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.2406 - accuracy: 0.9232\n",
      "Epoch 20/60\n",
      "2625/2625 [==============================] - 11s 4ms/step - loss: 0.2335 - accuracy: 0.9255\n",
      "Epoch 21/60\n",
      "2625/2625 [==============================] - 11s 4ms/step - loss: 0.2272 - accuracy: 0.9284\n",
      "Epoch 22/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.2238 - accuracy: 0.9284\n",
      "Epoch 23/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.2159 - accuracy: 0.9305\n",
      "Epoch 24/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.2104 - accuracy: 0.9330\n",
      "Epoch 25/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.2080 - accuracy: 0.9338\n",
      "Epoch 26/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.2036 - accuracy: 0.9357\n",
      "Epoch 27/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1996 - accuracy: 0.9365\n",
      "Epoch 28/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1959 - accuracy: 0.9372\n",
      "Epoch 29/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1935 - accuracy: 0.9388\n",
      "Epoch 30/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1906 - accuracy: 0.9394\n",
      "Epoch 31/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1872 - accuracy: 0.9409\n",
      "Epoch 32/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1818 - accuracy: 0.9420\n",
      "Epoch 33/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1800 - accuracy: 0.9430\n",
      "Epoch 34/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1776 - accuracy: 0.9433\n",
      "Epoch 35/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1753 - accuracy: 0.9438\n",
      "Epoch 36/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1735 - accuracy: 0.9452\n",
      "Epoch 37/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1714 - accuracy: 0.9452\n",
      "Epoch 38/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1667 - accuracy: 0.9466\n",
      "Epoch 39/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1648 - accuracy: 0.9474\n",
      "Epoch 40/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1620 - accuracy: 0.9486\n",
      "Epoch 41/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1614 - accuracy: 0.9484\n",
      "Epoch 42/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1584 - accuracy: 0.9488\n",
      "Epoch 43/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1550 - accuracy: 0.9509\n",
      "Epoch 44/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1541 - accuracy: 0.9512\n",
      "Epoch 45/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1555 - accuracy: 0.9503\n",
      "Epoch 46/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1491 - accuracy: 0.9532\n",
      "Epoch 47/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1489 - accuracy: 0.9526\n",
      "Epoch 48/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1465 - accuracy: 0.9539\n",
      "Epoch 49/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1433 - accuracy: 0.9547\n",
      "Epoch 50/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1440 - accuracy: 0.9548\n",
      "Epoch 51/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1415 - accuracy: 0.9544\n",
      "Epoch 52/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1383 - accuracy: 0.9559\n",
      "Epoch 53/60\n",
      "2625/2625 [==============================] - 11s 4ms/step - loss: 0.1424 - accuracy: 0.9547\n",
      "Epoch 54/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1385 - accuracy: 0.9554\n",
      "Epoch 55/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1381 - accuracy: 0.9565\n",
      "Epoch 56/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1371 - accuracy: 0.9568\n",
      "Epoch 57/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1337 - accuracy: 0.9574\n",
      "Epoch 58/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1321 - accuracy: 0.9578\n",
      "Epoch 59/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1311 - accuracy: 0.9587\n",
      "Epoch 60/60\n",
      "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1273 - accuracy: 0.9598\n"
     ]
    }
   ],
   "source": [
    "# Train the model again pleeeeease with all you got .... especially the new transformed data matrix X \n",
    "history_full = model_full.fit(training_ds_all, epochs=60, callbacks=[tensorboard_cb_f, checkpoint_cb_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAk3klEQVR4nO3de3RcZ33u8e9v7rqMJMu62JadyEmci+04TnCcpNwCJeAAh6QthxJKuRROkha64HBOIZyelsWia7U9LS3tApqTpoFFW0gohDRNQxxCKSEHQuzc7fgSJ3Zs2ZYlWdZ9NNf3/LH3SGNZtmR75NEePZ+19toze7Zmfq8vz7x69+U15xwiIhJ8oUoXICIi5aFAFxGpEgp0EZEqoUAXEakSCnQRkSoRqdQHt7S0uM7Ozkp9vIhIID399NN9zrnW6V6rWKB3dnaydevWSn28iEggmdlrJ3tNQy4iIlVCgS4iUiUU6CIiVUKBLiJSJRToIiJVYsZAN7N7zKzHzLbNsN/VZpY3s/eWrzwREZmt2fTQvwlsOtUOZhYG/hzYXIaaRETkDMwY6M65x4H+GXb7feD7QE85ijqVXd3D/OXmXfSPZub6o0REAuWsx9DNrAP4NeDOWex7q5ltNbOtvb29Z/R5e/tG+OpP9nBkaPyMfl5EpFqV46DoV4DPOefyM+3onLvLObfBObehtXXaK1dnVB+PAjCSzp3Rz4uIVKtyXPq/AbjXzABagHeaWc4590AZ3vsE9Qmv5JFxBbqISKmzDnTn3MriYzP7JvDQXIU5QH3cK3lYPXQRkePMGOhm9h3geqDFzLqALwBRAOfcjOPm5ZZUD11EZFozBrpz7pbZvplz7iNnVc0sFHvoI+nsXH+UiEigBO5K0dpYGDMYVg9dROQ4gQt0M6M+HlGgi4hMEbhAB0jGIzptUURkikAGen0iooOiIiJTBDPQ1UMXETlBIAM9mYjqPHQRkSkCGejekItOWxQRKRXIQNdBURGREwUy0OvjOigqIjJVMAM9EWE0kydfcJUuRURk3ghmoPuX/49m1EsXESkKZKDrBl0iIicKZKBrkgsRkRMFM9D9Hrru5yIiMimYgT5xC10FuohIUSADXWPoIiInCmSga5ILEZETBTPQNYYuInKCQAZ6XUxj6CIiUwUy0MMhoy4WVg9dRKREIAMdNMmFiMhUwQ103XFRROQ4Mwa6md1jZj1mtu0kr/+Wmb3gLz83syvKX+aJ6jXJhYjIcWbTQ/8msOkUr+8F3uycWwd8CbirDHXNKBnXJBciIqVmDHTn3ONA/yle/7lz7pj/9ElgeZlqOyUNuYiIHK/cY+gfA354shfN7FYz22pmW3t7e8/qg3RQVETkeGULdDN7C16gf+5k+zjn7nLObXDObWhtbT2rz6uPRzSGLiJSIlKONzGzdcDdwI3OuaPleM+ZJBPekItzDjM7Fx8pIjKvnXUP3czOA+4Hfts5t/vsS5qdZCKCczCWyZ+rjxQRmddm7KGb2XeA64EWM+sCvgBEAZxzdwJ/DCwGvu73lHPOuQ1zVXBR6SQXdfGy/KIhIhJoMyahc+6WGV7/OPDxslU0S6U36GpvONefLiIy/wT2StGkJrkQETlOYAO9XpNciIgcJ7iBrkkuRESOE/hA1y10RUQ8gQ30iXlFNYYuIgIEONCLpypqDF1ExBPYQI+GQySiIfXQRUR8gQ108C4uGlIPXUQECHigF+/nIiIiAQ/0ek1yISIyIfiBrh66iAgQ9EBPRHQeuoiIL9CBnlQPXURkQqADvV4HRUVEJgQ70OPevKLOuUqXIiJSccEO9ESEXMGRzhUqXYqISMUFOtCTukGXiMiEQAd6vW7QJSIyIdiBXpxXVD10EZGgB7o/5KJJLkREgh3oSU1DJyIyoToCXWPoIiIzB7qZ3WNmPWa27SSvm5n9rZntMbMXzOyq8pc5vcl5RRXoIiKz6aF/E9h0itdvBFb5y63A3519WbNTPMtFpy2KiMwi0J1zjwP9p9jlJuBbzvMk0GRmS8tV4KnEI2FiYc1aJCIC5RlD7wAOlDzv8redwMxuNbOtZra1t7e3DB/t389FPXQRkbIEuk2zbdqbqzjn7nLObXDObWhtbS3DR+ue6CIiReUI9C5gRcnz5cChMrzvrNTHIwxr1iIRkbIE+oPAh/yzXa4FBp1zh8vwvrOiSS5ERDyRmXYws+8A1wMtZtYFfAGIAjjn7gQeBt4J7AHGgI/OVbHTScYjdA+Nn8uPFBGZl2YMdOfcLTO87oBPlK2i01SfiDDSqx66iARAIQ+5cbAQRGvK/vYzBvp8V5zkQkTmiVwGzCAU8dalCnnIjkFmzFvnMyVL1lsX8v7OU86tsLAXhCF/DZAZnXy/zAjk0hCOemEZSUyunYNC1vuMQhbyOS9Yc2nIpbx1NuW9ViiAy4MreLW4PBRy3s8USpeS1wp5b8mnvTbkMv7jrPc52XFvXfCP973hM/C2L5T9jz74gZ6IMKyzXGShKBQmQyOf9YIon/YDI+WtsykvPMALVAsB/toV/KUksLJjkBqA8YHJdTblhWBx/2K4hmNeYIbj3toMRo/CaK+/9EFmeLLeUARCUW9drHu+mqg17H15hELen5mFvbaGwpNtCYX9JeLv62+L1UMk7v85xbzHkThEavx1AqIJWH71nDQh8IGejEfI5Aqkc3nikXCly5FqUChAdtTvRY5O9t5Ke3MTvbv0ZKhOhGVxcZO9uXx2cp3zQzeb8t4/m/Jemyqf9cI2m5rsic5pIBokGqGmCaK1fo/YJr8UnJvsRRd7n64AtYuhrhU6Xueta5u99ypkj297OAaxOq/XHK3xQi6amAy/UMRfh5k4G7rYw5/4cin5IgL//Won15G4/2ecmvySy6X9nn3ED+aoty4GbHEJBz4Ogx/oxfu5jKYV6FWpUPD+U6aH/WXIX48c/2v61MeF3OTjzJgXiJkRfxn1QjWfK/k13P8VPDPmfV45hSLH9/6KgRYtCbdwdPqfi9ZCrNZbF5dIbDIEi0s04b9WHGaIAzbZuy5+wZj5PcrwZO8zWuOFeCzp9UolsIIf6InJSS6a62IVrmYBy+dgrA/GjvohUsI5r3c5PliyDHi/3o8dhbF+SPV7jyeCOuP1rFx+uk+bHQv7vUK/BxdL+ut6qG3xemTF3loo4oVgrM4L2ljdZJCWhmTpr86lPbzir+QWOn6IIxQ+cRxZZI4EP9A1yUX55NJeoGZGvF5wcV3sGacGIHXMD+NjXhCP9sFoj/d4+guETy5a6/26XrPI+zW9cQXEk5NjkKXreIO/JP2lfnIcd6KnGp1ch6LqbcqCE/hA1yQXJ+GcF8KjfZMHrEaOwHD35DLS7YV0etgbhijM4ksxFPUCuLgsvhDOv84bO61r9QJ66vCBc16PN9HkjdEmGiHR4A8LiEi5BD7QF+Q90YvDGyM9XkgP7IfBAzDYBQP+erRn+gNoFoK6NkgugYYOaL/c6+3G6r3QjSe9x/F6/3Fy8nHNIv9gmYYQROaj4Ad6Nc1a5JwXzEe2w7F9k+PLY0e9MebRo15Qj/ZxwvBGKOIFdNN5sPKNUN8+2Wuu889CKG4L6eCxSDUKfKAni2PoQRpycQ6GD0Pfy3B0D/TuhO5tXpCnByf3s5A/tNHsDWUs6oQVG6G+zVvq2ryQblzu9bgV1CILWuADfd730EePQvfz0P2it/TuhKOveucfF8XqoX0NXP4b0L7WW1pWeWPOOrAnIrMU+ECviYYJh6zyB0ULBRjYNxnc3dug+wUYOji5T+MKaLsMOt/oHUxcfJG3JJcpuEXkrAU+0M2sMpNcZMbgwJOw92ew/xdeiGdG/KLCXg/7/NfD0nWwZB0sudy/gk5EZG4EPtChOMnFHAd6IQ8Hn4Y9j3kh3rXFO80vFIFlV8L6D3ih3b7W64XPwZ3UREROpSoCPZmIMDIXFxalBuCV/4Ddm2HPj7yzTSwES9fDdb8HnW+C8671TusTEamwqgj0svbQCwV49Sew5W54+VHvHh81i2DV273lol/1nouIzDPVEeiJCP2jZ3kXutQxeO7bsOUfoP8V714f1/4eXPpuWL5BpwSKyLxXHYEej7D/6NiZ/fDQYfjZl+HZf/LusrfiGrj+Dlh9ky5NF5FAqYpAT57JJBdj/fDEX8NTd3nDKle8HzbeCkuvmJsiRUTmWFUE+mlNQzc+BE9+HX7+Ve80w3W/6fXIm1fObZEiInOsSgI9SiqbJ5cvEAmf4gKdo6/At26Gwf1w2X+Bt/yhd4qhiEgVqI5AT0zOWtRYe5JAP7LdC3OXh995FM675twVKCJyDszqenMz22Rmu8xsj5ndMc3rjWb2b2b2vJltN7OPlr/Uk0vONMlF19PwjXd6FwF99BGFuYhUpRkD3czCwNeAG4HVwC1mtnrKbp8AXnLOXQFcD3zZzM7ZfHCnvEHX3p/Bt97jzZn4Oz+E1ovPVVkiIufUbHroG4E9zrlXnXMZ4F7gpin7OCBpZgbUA/3AObu5ysQkF1MPjO5+FP75vd7tZT/6iHf7WRGRKjWbQO8ADpQ87/K3lfoqcBlwCHgR+JRzU2cKnjvFHvpxpy72vwr3fRBaL4GPPAwNS89VOSIiFTGbQJ9uvrGpswG/A3gOWAasB75qZg0nvJHZrWa21cy29vb2nmapJ7e4zhvdOTI4Prlx8//25ra85T5vxh4RkSo3m0DvAlaUPF+O1xMv9VHgfufZA+wFLp36Rs65u5xzG5xzG1pbW8+05hOsWFRLfTzCS4eHvA17HoNd/w5v+gP1zEVkwZhNoG8BVpnZSv9A5/uBB6fssx/4VQAzawcuAV4tZ6GnEgoZq5c2sO3gIOSz8MjnofkCuPZ3z1UJIiIVN2OgO+dywCeBzcAO4LvOue1mdruZ3e7v9iXgV8zsReDHwOecc31zVfR01nQ0sOPwMIVf/l/o2w2b/kz3YhGRBWVWFxY55x4GHp6y7c6Sx4eAt5e3tNOzZlkjddnncf/5Z3DRDXDxOypZjojIOVc1E1mu7Wjgf0buw7Ip2PSnlS5HROScq5pAvyj7Mu8L/5Rftr/Pm89TRGSBqY5ALxSIbL6DwVAjf897K12NiEhFVEegdz8PXU/x046Ps7U7h3NTT5MXEal+1RHoPTsACF3wJobGc3QdS1W4IBGRc686Ar13J4RjnH/hGgDvfHQRkQWmSgJ9FyxexSXLFhEOGdsPDVW6IhGRc646Ar1nB7ReQiIaZlVbPdsOqYcuIgtP8AM9MwoD+yemkluzrJFtB9VDF5GFJ/iB3vcy4Lzb5OJdYNQ3kqZnaPzUPyciUmWCH+i9O711q3dzxzXLGgE07CIiC051BHoo6t1dEVi9zLsN+3YNu4jIAlMFgb4LFl/kTWaBNx3dypY69dBFZMGpgkDfOTF+XrRmWYMOjIrIghPsQM+moH/vxPh50dqORg4OpBgYy1SoMBGRcy/YgT7lDJeiNcVxdF1gJCILSLADvXeXt/bPQS8qnumyXePoIrKABDzQd4KFofnC4zY318XoaKrROLqILCjBD/TFF0IkdsJLq5c16EwXEVlQgh/oU8bPi9Yua2Rv3yij6dw5LkpEpDKCG+i5NPS/Cq2XTfvy2o4GnIMdhzXsIiILQ3AD/egecIWT9tCLB0Zf6NKwi4gsDLMKdDPbZGa7zGyPmd1xkn2uN7PnzGy7mf20vGVOw5+laOo56EXtDXEuaK1j8/buOS9FRGQ+mDHQzSwMfA24EVgN3GJmq6fs0wR8HXiPc24N8F/LX+oUvbvAQt5l/9MwM266ooNf7u3n0ICmpBOR6jebHvpGYI9z7lXnXAa4F7hpyj4fAO53zu0HcM71lLfMafTu9G7IFU2cdJeb1i8D4MHnD815OSIilTabQO8ADpQ87/K3lboYWGRm/2lmT5vZh8pV4En17jrpcEtRZ0sd61c08cCzB+e8HBGRSptNoNs029yU5xHgdcC7gHcAf2RmF5/wRma3mtlWM9va29t72sVOyGWg/5WTHhAtdfP6ZezsHmZX9/CZf56ISADMJtC7gBUlz5cDU8cwuoBHnHOjzrk+4HHgiqlv5Jy7yzm3wTm3obW19Uxr9sK8kDvpKYul3n3FMsIh44Hn1EsXkeo2m0DfAqwys5VmFgPeDzw4ZZ9/Bd5oZhEzqwWuAXaUt9QSE7MUzdxDb6mP84aLWnjwuUMUClN/sRARqR4zBrpzLgd8EtiMF9Lfdc5tN7Pbzex2f58dwCPAC8BTwN3OuW1zVnXvLsCgZdWsdr/5ymUcHEix9bVjc1aSiEilRWazk3PuYeDhKdvunPL8L4C/KF9pp9CzAxZ1QrRmVru/ffUSaqLbeOC5g2xc2Ty3tYmIVEgwrxTt3XXCLXNPpS4e4YbV7Tz84mEyucIcFiYiUjnBC/R81rvsfxbj56VuvnIZA2NZHt99FmfXiIjMY8EL9P5XoZCd8Rz0qd64qpXmupjOdhGRqhW8QD+NM1xKRcMh3nX5Uh7bcYQR3VJXRKpQ8AJ96Xp4119By+kFOni3AhjPFti8TTfsEpHqE7xAX3Q+XP0xiNWe9o++7vxFnL+4lruf2Ete56SLSJUJXqCfBTPjs++4lB2Hh/j2U/srXY6ISFktqEAHeOflS7jugsV8+dFdHBvNVLocEZGyWXCBbmZ88aY1DI/n+MtHd1W6HBGRsllwgQ5wcXuSD113Pt9+aj/bDmqKOhGpDgsy0AE+/baLaa6N8YUHt+OcDpCKSPAt2EBvrInyuRsv5enXjvEDTYAhIlVgwQY6wHuvWs76FU386Q93MjyerXQ5IiJnZUEHeihkfPE9a+gbSfOVx16udDkiImdlQQc6wBUrmvjAxvP4hyf28uMdRypdjojIGVvwgQ7wR+9ezZplDfz3+57jtaOjlS5HROSMKNCBRDTMnR98HWbGbf/4NKlMvtIliYicNgW6b0VzLX97y5XsOjLM//rBizqVUUQCR4Fe4s0Xt/KZt13MD549yLd+8VqlyxEROS0K9Ck+8ZaLeNtlbXzpoZfYuq+/0uWIiMyaAn2KUMj48vvWs3xRDbf/0zO8fGS40iWJiMyKAn0ajTVR7v7w1ZjBb971JC8dGqp0SSIiM5pVoJvZJjPbZWZ7zOyOU+x3tZnlzey95SuxMi5qq+e7t11HIhLilr9/kucPDFS6JBGRU5ox0M0sDHwNuBFYDdxiZqtPst+fA5vLXWSlrGyp477brqOhJsJv3f1LjamLyLw2mx76RmCPc+5V51wGuBe4aZr9fh/4PtBTxvoqbkVzLd+97TraknE+dM9T/PyVvkqXJCIyrdkEegdwoOR5l79tgpl1AL8G3Fm+0uaPpY013HvbtSxfVMNHvrGFB3R3RhGZh2YT6DbNtqlX3XwF+Jxz7pSXWJrZrWa21cy29vb2zrLE+aEtmeDeW69j/YomPn3fc/zJQy+RyxcqXZaIyITZBHoXsKLk+XLg0JR9NgD3mtk+4L3A183s5qlv5Jy7yzm3wTm3obW19cwqrqDmuhj//PFr+PB153P3E3v5yDe2aF5SEZk3ZhPoW4BVZrbSzGLA+4EHS3dwzq10znU65zqB7wG/55x7oNzFzgfRcIgv3rSW//Mb63hqbz/v+doT7Dis0xpFpPJmDHTnXA74JN7ZKzuA7zrntpvZ7WZ2+1wXOF+97+oV3HvbtaSzBX796z/nnif2aghGRCrKKnUTqg0bNritW7dW5LPLqWdonD/43gv8dHcvly1t4E9uXsPrzm+udFkiUqXM7Gnn3IbpXtOVomeprSHBNz96NXd+8CoGxjL8xt/9gs9+73mOjqQrXZqILDAK9DIwMzatXcpjn3kzt735Au5/5iBv/fJP+e6WA7oNr4icMwr0MqqLR/j8jZfxw0+9kUvak3z2+y/woXueouvYWKVLE5EFQIE+B1a1J7n31mv50k1rePq1Y7zjrx/nH598jUJBvXURmTsK9DkSChm/fV0nmz/9Jq46fxF/9MA2bvn7J9l2cFDDMCIyJ3SWyzngnONftnbxpX9/ieHxHJe0J/m1qzq4eX0HSxoTlS5PRALkVGe5KNDPocGxLP/2wiF+8OxBnn7tGGbw+gtbuGXjedy4dgmh0HR3WRARmaRAn4f29Y3yg2cPcv+zXRzoT3HpkiSfueFibljdjpmCXUSmp0Cfx/IFx0MvHOKvf7SbfUfHWLe8kc/ccDFvvrhVwS4iJ1CgB0AuX+D+Zw/yN4+9zMGBFFcsb+Sm9R28a91S2hs0zi4iHgV6gGRyBe7beoBv/3I/Ow4PYQYbO5t59xXLuHHtElrq45UuUUQqSIEeUHt6RnjohUP82/OHeKV3FDO4vKORN1zUwhtXtXLV+U3EI+FKlyki55ACPeCcc+zsHubR7Ud4Yk8vz+wfIF9w1ETDXHtBM29fs4QbVrer9y6yACjQq8zweJZfvHKUJ/b08ZNdPRzoT2EGV3c2s2nNEt6xdgkdTTWVLlNE5oACvYoVe++PbOtm8/ZudnYPA3Bxez2vv6iFN1zUwjUXLKY+HqlwpSJSDgr0BWRf3yiPvtTNz17u46m9/aRzBSIhY/2KJt5yaRub1i7hwtb6SpcpImdIgb5AjWfzPLP/GE+83MfPXu7jxYODgNd737R2KTeuXcKlS5I6310kQBToAsChgRSbt3fzw23dbNnXj3PQkIiwormWFYtqWdFcw/JFtXS21HHpkiRtybjCXmSeUaDLCXqH0zy24wjbDw3SdSzFgf4xuo6lSOcm50Vtqo1ySXuSy5Y2cNnSJOuWN3Fxe5Kw7jkjUjGnCnQdKVugWpNxbtl43nHbCgVH32iaV3pG2dU9xK4jw+zsHuZfth5gNJMHoDYW5vKORtavaOKKFU2sXdbIiuYa9eRF5gEFukwIhYy2ZIK2ZILrLlw8sb1QcLzWP8bzBwZ47sAAzx4Y4Bv/bx+ZvNebT8YjXLa0gdXLGli9tIGORTW0NyRob4hTH48o7EXOEQW6zCgUMla21LGypY6br+wAIJ3Ls6t7mO2Hhnjp0BDbDw1y35YDpLL54362NhZmSUOCy5Y1sLGzmY0rm7mkPalbBYvMgVkFupltAv4GCAN3O+f+bMrrvwV8zn86Avyuc+75chYq80s8Embd8ibWLW+a2JYvOA70j3F4cJwjQ8UlzeHBFM+8dox/f+Ew4B2I3dDZzLrljaxqS7KqvZ7OxXXEIppAS+RszBjoZhYGvgbcAHQBW8zsQefcSyW77QXe7Jw7ZmY3AncB18xFwTJ/hUNGZ0sdnS11J7zmnKPrWIot+/p5am8/T+3r5ye7eigekw+HjM7FtZzXXMui2hhNtTEW1UZpqovRWh9j+aJazltcS0Mieo5bJRIcs+mhbwT2OOdeBTCze4GbgIlAd879vGT/J4Hl5SxSgs/MvNMjm2v59au8fx6pTJ5Xekd4pXeEl4+MsPvIMIcGU+w+MsLAWGbiQGypptooKxZ5wd+xqIZljQk6FtXS0VRDx6IaGhIas5eFazaB3gEcKHnexal73x8Dfng2RcnCUBMLs7ajkbUdjdO+ns7lGRzL0jOcpuvYGPv7i0uKHYeH+NGOI2RKTrMEqIuFWdKYYFlTDUsaEixtTLC4Pk5TbZTGmuhEz39RXYykDthKlZlNoE/3L37ak9fN7C14gf6Gk7x+K3ArwHnnnTfdLiIT4pEwbQ1h2hoS04a+c46+kQwHB1IcPJbi4IA3ft89OM7hwXF2H+mlZzjNyS61iEVCtNTFWFwfZ3F9jNb6+MTZOW0NCdobEixrStBarwusJBhmE+hdwIqS58uBQ1N3MrN1wN3Ajc65o9O9kXPuLrzxdTZs2FCZK5qkapgZrck4rck461c0TbtPLl9gaDzHwFiGY2NZBlMZjo1mOTaWoXckzdGRDEdH0vSNZNh5eJjekTT5wvH/NBsSEVa1J1nVVs9Fbd4B3IaaKPXxCMlEhPp4hPpEhGhYB3WlsmYT6FuAVWa2EjgIvB/4QOkOZnYecD/w28653WWvUuQMRcIhmutiNNfFZrV/vuA4OpqmZyjNkaFx9vePsadnhD09I/zopSPcu+XASX+2Lhb2hnTqojTVxGiqjU4M9TTWeNsaaqI0JLwvgOIXQTIeJREN6bcAOWszBrpzLmdmnwQ24522eI9zbruZ3e6/fifwx8Bi4Ov+P8rcyS5NFZnPwiUXV003zNM/mmF//xgj4zlG0lmGx3OMpHMMj+cYGMsyMJZhIOX9BnBwIMVgKstgKntCr3+qaNhoSHjB3+AvLfUxOhd7Zw11Lq7l/MV1NNboLB85Od3LRWSOOecYSXuBP5ia/BIYSWcZGc8x7H8hDKayDPlfAEOpLEeG0nQPjR/3XslEhIZE9LihnmQiyuK6mLfUx2mui7G4PkY8EiIcMiKh4tr8A8NR/TYQYLqXi0gFmRnJRJRkInrcwajZGM/mee3oGPuOjrKvb5RDAymG0znvi2A8x9GRDHv7RukfyTCczs3qPaNhY3FdnJakdyC4LekdCG5vTNCeTLCkMUFjTZR4JETMX6LhECEzUtk8qUye8WyesUweh6NzcR2JqOa2nQ8U6CLzWCIa5pIlSS5Zkpxx33QuT/9ohqMjGfpHM2TzBXIFR77gvMd5x0AqS99Imr7hNL0j3rL90BB9I2lmGBU6qUjIuKitntXLGlizrJHLliSpjUcIGRiGGYTMSCYiNNVGdX+fOaRAF6kS8UiYpY01LG08/flkc/kCfSMZuoe80z6HUlky+QKZXIGsvy44qImFqImGqYlFqImGyRUKE/f0eXx3H/c/c3DGz4qEzD9g7A0TtTV4p4a2NcRprY9TFw+TyTuy/mdn8wXMvJ9pLl5FXBdlUW1sxt8MxjI5ugfHaajxhqWq/YtEgS4iRMIhljR6wy2nPS5UomdonN1HRsjmCxSco+Dw1gXHcDrH4Jh3wHgg5R1A7hvOsO3gID1D49NeGTyThkSE1qQ3bNTWEKexJkrvcJquYykODqToH81M7BuPhOhoqmFZUw0dTTXUxSOEQ97N58JmhENGNOwPM4Unh5uS8Yh/XYJ3imw8Mn+HlxToIlI2bQ0J2hoSZ/Szo+kcPcNpUpn8RKhGI95B3YJzDPhfBsdGvWsK+kfT9PpDRz1DaZ7dP8DAWIbWZJzli2q5fHkjHU01LG1MMJTKcmhw3L8ALcVPdvUwlsmTLzjy/hdObpZjTs11MVrqY9TFvQPTtbEwdfEIdbEI8UiIeDREPBImHgmRiIZpTcZZ6l+93FIfn9MJYhToIjIv1MUjrIyfPJLaz/CL4nTk8oWJoaZMrkA6V2B4PEfP8OTdQ48MjdM3kmYsk2cknePI0Dij6TxjmRxp/2dOdppqJGS0NyT4yK908t/edEHZ61egi4j4IuEQkXCI2inXoa2m4bTep/jFMJbJ0+PfQvrQ4DiHB1IcGkjR1hAvY9WTFOgiImU2+cUQoaU+zuplp/eFcKZ08wkRkSqhQBcRqRIKdBGRKqFAFxGpEgp0EZEqoUAXEakSCnQRkSqhQBcRqRIVm+DCzHqB187wx1uAvjKWU2lqz/xVTW2B6mpPNbUFZt+e851zrdO9ULFAPxtmtrWaprhTe+avamoLVFd7qqktUJ72aMhFRKRKKNBFRKpEUAP9rkoXUGZqz/xVTW2B6mpPNbUFytCeQI6hi4jIiYLaQxcRkSkU6CIiVSJwgW5mm8xsl5ntMbM7Kl3P6TKze8ysx8y2lWxrNrMfmdnL/npRJWucLTNbYWY/MbMdZrbdzD7lbw9qexJm9pSZPe+354v+9kC2B8DMwmb2rJk95D8Pclv2mdmLZvacmW31twWyPWbWZGbfM7Od/v+f68rRlkAFupmFga8BNwKrgVvMbHVlqzpt3wQ2Tdl2B/Bj59wq4Mf+8yDIAf/DOXcZcC3wCf/vI6jtSQNvdc5dAawHNpnZtQS3PQCfAnaUPA9yWwDe4pxbX3K+dlDb8zfAI865S4Er8P6Ozr4tzrnALMB1wOaS558HPl/pus6gHZ3AtpLnu4Cl/uOlwK5K13iG7fpX4IZqaA9QCzwDXBPU9gDL/WB4K/CQvy2QbfHr3Qe0TNkWuPYADcBe/JNSytmWQPXQgQ7gQMnzLn9b0LU75w4D+Ou2Ctdz2sysE7gS+CUBbo8/RPEc0AP8yDkX5PZ8BfgsUCjZFtS2ADjgUTN72sxu9bcFsT0XAL3AN/zhsLvNrI4ytCVogW7TbNN5lxVmZvXA94FPO+eGKl3P2XDO5Z1z6/F6txvNbG2FSzojZvZuoMc593Slaymj1zvnrsIbcv2Emb2p0gWdoQhwFfB3zrkrgVHKNFQUtEDvAlaUPF8OHKpQLeV0xMyWAvjrngrXM2tmFsUL8392zt3vbw5se4qccwPAf+Id7whie14PvMfM9gH3Am81s38imG0BwDl3yF/3AD8ANhLM9nQBXf5vfwDfwwv4s25L0AJ9C7DKzFaaWQx4P/BghWsqhweBD/uPP4w3Fj3vmZkB/wDscM79VclLQW1Pq5k1+Y9rgLcBOwlge5xzn3fOLXfOdeL9P/kP59wHCWBbAMyszsySxcfA24FtBLA9zrlu4ICZXeJv+lXgJcrRlkofIDiDAwrvBHYDrwB/WOl6zqD+7wCHgSzeN/XHgMV4B69e9tfNla5zlm15A96Q1wvAc/7yzgC3Zx3wrN+ebcAf+9sD2Z6Sdl3P5EHRQLYFb9z5eX/ZXvy/H+D2rAe2+v/WHgAWlaMtuvRfRKRKBG3IRURETkKBLiJSJRToIiJVQoEuIlIlFOgiIlVCgS4iUiUU6CIiVeL/A8sxR1o51Ln5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history_full.history))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Prediction of Unknown Data (Test Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peparing Test Data\n",
    "As well as previously done, we need to create a TF dataset of the test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting dataframe format into tensorflow compatible format.\n",
    "X_test = X_test.values.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(X_test, tf.float32)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (28, 28, 1), types: tf.float32>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_dataset.batch(32).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Competition File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_competition_file = pd.DataFrame(columns=['ImageId','Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of Testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the image\n",
    "plt.figure(figsize=(12, 12))\n",
    "for X_batch in test_ds.take(1):\n",
    "    for index in range(1):\n",
    "        plt.subplot(3, 3, index + 1)\n",
    "        plt.imshow(X_batch[index])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propability of all lables for given pixels:  [2.4089815e-08 7.4411575e-05 9.9990892e-01 5.6008630e-06 4.7317304e-08\n",
      " 2.3272852e-07 7.5315036e-08 1.0460487e-05 1.8115448e-07 1.3897583e-09]\n"
     ]
    }
   ],
   "source": [
    "for element in test_ds.take(1):\n",
    "    print(\"Propability of all lables for given pixels: \", model_full.predict(test_ds.take(1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Digit:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted Digit: \",np.argmax(model_full.predict(test_ds.take(1))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_full.predict(test_ds)                                                                           # predict the probability\n",
    "predictions = np.argmax(predictions, axis=1)                                                                        # getting the predicted digit numbers based ont the probability of every np element \n",
    "mnist_competition_file = pd.DataFrame(predictions)                                                                  # converting into df\n",
    "mnist_competition_file.index += 1                                                                                   # index should start at 1\n",
    "mnist_competition_file.reset_index(level=0, inplace=True)                                                           # make the index a column \n",
    "mnist_competition_file = mnist_competition_file.rename(columns={\"index\": \"ImageId\", 0: \"Label\"}, errors=\"raise\")    # renamen them according to the competition requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "0            1      2\n",
       "1            2      0\n",
       "2            3      9\n",
       "3            4      9\n",
       "4            5      3\n",
       "...        ...    ...\n",
       "27995    27996      9\n",
       "27996    27997      7\n",
       "27997    27998      3\n",
       "27998    27999      9\n",
       "27999    28000      2\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_competition_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_competition_file.ImageId = mnist_competition_file.ImageId.astype(int)\n",
    "mnist_competition_file.Label = mnist_competition_file.Label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_competition_file.to_csv('mnist_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b49f70aa2f17b03439dc8f4bbaf601f728142d0d0d774f4bbd10ea7a16b86ea"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('wingpuflake_keras': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
